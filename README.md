# Financial Data ETL & Analytics Platform

A comprehensive financial data pipeline and analytics platform that extracts, processes, and analyzes stock market data with semantic search capabilities.

## Features

### Data Ingestion & Processing
- Price Data: Historical stock prices from Yahoo Finance (5+ years)
- News Data: Financial news articles with sentiment analysis
- SEC Filings: 10-K and 10-Q filings with section extraction (MD&A, Risk Factors)
- Earnings Transcripts: Earnings call transcripts with speaker segmentation
- Fundamentals: Financial statement data (income statements, balance sheets)

### ETL Pipeline
- Automated Workflow: End-to-end Extract, Transform, Load pipeline
- Data Cleaning: Normalized column names, date handling, gap filling
- Feature Engineering: 
  - Technical indicators (returns, momentum, volatility)
  - News sentiment aggregation
  - Text embeddings for semantic search
- Vector Indices: FAISS-based vector stores for efficient similarity search

### Semantic Search
- Vector Retrieval: Search across news, filings, and transcripts using natural language
- Similarity Search: Find relevant documents based on semantic meaning
- Filtered Search: Search by ticker or document type
- Index Management: Rebuild indices on-demand

### AI Research Agent ðŸ¤–
- Natural Language Queries: Ask questions in plain English
- Intelligent Synthesis: Combines information from multiple sources
- Document Search: Automatically searches news, filings, and transcripts
- Source Citations: Provides references to source documents
- Conversational Interface: Chat-based interaction with context awareness

### Data Visualization
- Interactive Charts: Price charts with technical indicators
- Data Tables: Formatted tables for features, news, and fundamentals
- Number Formatting: Human-readable number formatting (K/M suffixes, decimals)

### Web Interface
- ETL Dashboard: Trigger and monitor ETL pipelines
- Data Explorer: Browse processed data by ticker
- Search Interface: Semantic search across financial documents
- AI Agent Chat: Conversational interface for research queries
- Status Monitor: Real-time pipeline status tracking

## Architecture

```
src/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/           # FastAPI REST API
â”‚   â”œâ”€â”€ etl/           # ETL orchestration
â”‚   â”œâ”€â”€ ingestion/     # Data extraction modules
â”‚   â”œâ”€â”€ processing/    # Data transformation
â”‚   â”œâ”€â”€ retrieval/     # Vector search system
â”‚   â””â”€â”€ utils/         # NLP and text processing utilities
â””â”€â”€ frontend/          # React + Vite frontend
```

## Quick Start

### Prerequisites
- Python 3.9+
- Node.js 16+
- API keys:
  - OpenAI API key (for AI agent) - set in `.env` as `OPENAI_API_KEY` (required for agent)
  - Alpha Vantage API key (for fundamentals) - set in `.env` as `AV_API_KEY` (optional)

### Backend Setup

1. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up environment variables:
```bash
# Create .env file
echo "OPENAI_API_KEY=your_openai_key" > .env
echo "AV_API_KEY=your_alpha_vantage_key" >> .env  # Optional
```

**Note**: The OpenAI API key is required for the AI Agent feature. Get your key from https://platform.openai.com/api-keys

4. Start API server:
```bash
cd src/backend/api
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Setup

1. Install dependencies:
```bash
cd src/frontend
npm install
```

2. Start development server:
```bash
npm run dev
```

The frontend will be available at `http://localhost:5173`

### Running ETL Pipeline

Via API:
```bash
curl -X POST http://localhost:8000/api/etl/run/AAPL
```

Via Python:
```bash
python test_etl.py
```

## API Endpoints

### Data Endpoints
- `GET /api/ticker/{ticker}/features` - Get processed features
- `GET /api/ticker/{ticker}/prices` - Get price data
- `GET /api/ticker/{ticker}/news` - Get news articles
- `GET /api/ticker/{ticker}/fundamentals` - Get fundamentals

### ETL Endpoints
- `POST /api/etl/run/{ticker}` - Run ETL pipeline
- `GET /api/etl/status/{ticker}` - Get pipeline status

### Search Endpoints
- `GET /api/search?query=...&k=10` - Semantic search across all documents
- `GET /api/search/news?query=...&ticker=AAPL` - Search news
- `GET /api/search/filings?query=...&ticker=AAPL` - Search filings
- `GET /api/search/transcripts?query=...&ticker=AAPL` - Search transcripts
- `POST /api/search/rebuild-indices` - Rebuild vector indices

### Agent Endpoints
- `POST /api/agent/query` - Query the research agent with natural language
- `POST /api/agent/research` - Research a specific topic
- `GET /api/agent/status` - Get agent system status

## Technology Stack

### Backend
- FastAPI: REST API framework
- Pandas: Data processing
- FAISS: Vector similarity search
- Sentence Transformers: Text embeddings
- VADER: Sentiment analysis
- OpenAI: LLM for AI agents
- yfinance: Stock price data
- secedgar: SEC filings access

### Frontend
- React: UI framework
- Vite: Build tool
- Tailwind CSS: Styling
- Recharts: Data visualization
- Axios: HTTP client

## Data Flow

1. Extract: Fetch data from APIs (Yahoo Finance, SEC EDGAR, earningscall)
2. Transform: Clean, normalize, and compute features
3. Load: Save processed data and build vector indices
4. Search: Query vector indices for semantic search

## Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ api/              # FastAPI application
â”‚   â”‚   â”œâ”€â”€ etl/              # ETL orchestration
â”‚   â”‚   â”œâ”€â”€ ingestion/        # Data extraction
â”‚   â”‚   â”œâ”€â”€ processing/       # Data transformation
â”‚   â”‚   â”œâ”€â”€ retrieval/        # Vector search
â”‚   â”‚   â””â”€â”€ utils/            # Utilities
â”‚   â””â”€â”€ frontend/             # React application
â”œâ”€â”€ data/                     # Data storage (gitignored)
â”œâ”€â”€ test_etl.py              # ETL test script
â”œâ”€â”€ test_vector_retrieval.py # Vector search test
â””â”€â”€ README.md                # This file
```

## AI Agent System

The platform includes an AI Research Agent that can answer questions about financial data using natural language. See [AGENT_SETUP.md](AGENT_SETUP.md) for detailed setup and usage instructions.

**Quick Start with Agent:**
1. Set `OPENAI_API_KEY` in your `.env` file
2. Navigate to `/agent` in the web interface
3. Ask questions like "What are the main risks for AAPL?" or "Search for AI-related news"

## AI Usage

This project was developed with moderate assistance from AI tools. AI was used to:
- Generate boilerplate code for API endpoints and React components
- Debug and fix data processing issues
- Refactor and clean up code structure
- Write documentation and README content
- Implement the agentic AI system for financial research

